{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n5clv_oNo3yZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class ConvLayer:\n",
        "    \"\"\"\n",
        "    A layer to perform convolution with multiple filters.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_filters, filter_size):\n",
        "        # num_filters: Number of kernels\n",
        "        # filter_size: An integer (e.g., 3 for a 3x3 filter)\n",
        "\n",
        "        self.num_filters = num_filters\n",
        "        self.filter_size = filter_size\n",
        "\n",
        "        # Initialize random filters. The depth is 1 for grayscale images.\n",
        "        # The weights are initialized randomly, in a real scenario they are learned.\n",
        "        self.filters = np.random.randn(num_filters, filter_size, filter_size) / (filter_size * filter_size)\n",
        "\n",
        "    def convolve2d(self, image, kernel):\n",
        "        \"\"\"Helper function for a single 2D convolution.\"\"\"\n",
        "        k_h, k_w = kernel.shape\n",
        "        img_h, img_w = image.shape\n",
        "\n",
        "        # Calculate output dimensions (assuming stride=1, padding=0)\n",
        "        out_h = img_h - k_h + 1\n",
        "        out_w = img_w - k_w + 1\n",
        "\n",
        "        output = np.zeros((out_h, out_w))\n",
        "\n",
        "        for y in range(out_h):\n",
        "            for x in range(out_w):\n",
        "                roi = image[y:y + k_h, x:x + k_w]\n",
        "                output[y, x] = np.sum(roi * kernel)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def forward(self, input_image):\n",
        "        \"\"\"\n",
        "        Performs a forward pass of the conv layer.\n",
        "\n",
        "        Args:\n",
        "            input_image (np.array): A 2D numpy array.\n",
        "\n",
        "        Returns:\n",
        "            np.array: A 3D array of feature maps.\n",
        "        \"\"\"\n",
        "        # We store the input for backpropagation later (not implemented here)\n",
        "        self.last_input = input_image\n",
        "\n",
        "        height, width = input_image.shape\n",
        "\n",
        "        # Calculate output dimensions\n",
        "        output_height = height - self.filter_size + 1\n",
        "        output_width = width - self.filter_size + 1\n",
        "\n",
        "        feature_maps = np.zeros((self.num_filters, output_height, output_width))\n",
        "\n",
        "        # Apply each filter to the input image\n",
        "        for i in range(self.num_filters):\n",
        "            feature_maps[i] = self.convolve2d(input_image, self.filters[i])\n",
        "\n",
        "        return feature_maps\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ReLU:\n",
        "    \"\"\"ReLU activation function layer.\"\"\"\n",
        "    def forward(self, input_data):\n",
        "        # Apply ReLU element-wise\n",
        "        self.last_input = input_data\n",
        "        return np.maximum(0, input_data)\n",
        "\n",
        "class MaxPoolingLayer:\n",
        "    \"\"\"\n",
        "    A layer to perform max pooling.\n",
        "    \"\"\"\n",
        "    def __init__(self, pool_size=2, stride=2):\n",
        "        self.pool_size = pool_size\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, feature_maps):\n",
        "        \"\"\"\n",
        "        Downsamples the feature maps.\n",
        "\n",
        "        Args:\n",
        "            feature_maps (np.array): A 3D array from the conv layer.\n",
        "\n",
        "        Returns:\n",
        "            np.array: A downsampled 3D array.\n",
        "        \"\"\"\n",
        "        self.last_input = feature_maps\n",
        "        num_filters, input_h, input_w = feature_maps.shape\n",
        "\n",
        "        # Calculate output dimensions\n",
        "        output_h = (input_h - self.pool_size) // self.stride + 1\n",
        "        output_w = (input_w - self.pool_size) // self.stride + 1\n",
        "\n",
        "        downsampled_maps = np.zeros((num_filters, output_h, output_w))\n",
        "\n",
        "        for i in range(num_filters):\n",
        "            for y in range(output_h):\n",
        "                for x in range(output_w):\n",
        "                    # Define the pooling window\n",
        "                    y_start = y * self.stride\n",
        "                    y_end = y_start + self.pool_size\n",
        "                    x_start = x * self.stride\n",
        "                    x_end = x_start + self.pool_size\n",
        "\n",
        "                    # Extract the window and find the max value\n",
        "                    window = feature_maps[i, y_start:y_end, x_start:x_end]\n",
        "                    downsampled_maps[i, y, x] = np.max(window)\n",
        "\n",
        "        return downsampled_maps\n",
        "\n",
        "\n",
        "\n",
        "class FlattenLayer:\n",
        "    \"\"\"Flattens the output of the pooling layer into a 1D array.\"\"\"\n",
        "    def forward(self, input_data):\n",
        "        self.last_input_shape = input_data.shape\n",
        "        # Flatten the multi-dimensional input into a 1D vector\n",
        "        return input_data.flatten()\n",
        "\n",
        "class DenseLayer:\n",
        "    \"\"\"\n",
        "    A fully connected layer for the ANN part.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_size):\n",
        "        # output_size is the number of classes (e.g., 10 for digits 0-9)\n",
        "        self.weights = np.random.randn(input_size, output_size) * 0.1\n",
        "        self.biases = np.zeros(output_size)\n",
        "\n",
        "    def forward(self, input_vector):\n",
        "        \"\"\"Performs the forward pass for the dense layer.\"\"\"\n",
        "        self.last_input = input_vector\n",
        "        # Standard ANN calculation: input * weights + biases\n",
        "        return np.dot(input_vector, self.weights) + self.biases\n"
      ],
      "metadata": {
        "id": "iBDsPno0paGL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Define a sample input image (e.g., a 10x10 grayscale image) ---\n",
        "sample_image = np.array([\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 0, 255, 255, 255, 255, 255, 255, 0, 0],\n",
        "    [0, 0, 255, 0, 0, 0, 0, 255, 0, 0],\n",
        "    [0, 0, 255, 0, 0, 0, 0, 255, 0, 0],\n",
        "    [0, 0, 255, 0, 0, 0, 0, 255, 0, 0],\n",
        "    [0, 0, 255, 255, 255, 255, 255, 255, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "])\n",
        "\n",
        "# --- 2. Initialize the layers of our network ---\n",
        "conv = ConvLayer(num_filters=8, filter_size=3) # 8 filters, each 3x3\n",
        "relu = ReLU()\n",
        "pool = MaxPoolingLayer(pool_size=2)\n",
        "flatten = FlattenLayer()\n",
        "\n",
        "# The input size for the dense layer depends on the output of the pooling layer\n",
        "# Conv output: 10-3+1 = 8x8. With 8 filters -> (8, 8, 8)\n",
        "# Pool output: (8-2)/2+1 = 4x4. With 8 filters -> (8, 4, 4)\n",
        "# Flattened size: 8 * 4 * 4 = 128\n",
        "dense = DenseLayer(input_size=128, output_size=10) # 10 output classes\n",
        "\n",
        "# --- 3. Run the forward pass step-by-step ---\n",
        "print(f\"Input image shape: {sample_image.shape}\\n\")\n",
        "\n",
        "# Pass through Convolutional Layer\n",
        "feature_maps = conv.forward(sample_image)\n",
        "print(f\"After Conv Layer (feature maps shape): {feature_maps.shape}\\n\")\n",
        "\n",
        "# Pass through ReLU Activation\n",
        "activated_maps = relu.forward(feature_maps)\n",
        "# Shape doesn't change here\n",
        "\n",
        "# Pass through Max Pooling Layer\n",
        "pooled_maps = pool.forward(activated_maps)\n",
        "print(f\"After Max Pooling Layer (downsampled maps shape): {pooled_maps.shape}\\n\")\n",
        "\n",
        "# Flatten the result\n",
        "flat_vector = flatten.forward(pooled_maps)\n",
        "print(f\"After Flatten Layer (vector length): {flat_vector.shape[0]}\\n\")\n",
        "\n",
        "# Feed into the ANN Dense Layer\n",
        "final_output = dense.forward(flat_vector)\n",
        "print(f\"Final ANN Output (logits for 10 classes):\\n {final_output}\")\n",
        "\n",
        "# To get final probabilities, you would apply a Softmax function\n",
        "def softmax(logits):\n",
        "    exps = np.exp(logits - np.max(logits)) # Subtract max for numerical stability\n",
        "    return exps / np.sum(exps)\n",
        "\n",
        "final_probabilities = softmax(final_output)\n",
        "predicted_class = np.argmax(final_probabilities)\n",
        "\n",
        "print(f\"\\nFinal Probabilities:\\n {np.round(final_probabilities, 3)}\")\n",
        "print(f\"\\nPredicted Class: {predicted_class}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoIrhgjj0MEs",
        "outputId": "91d192fd-0d20-42e7-cb27-c03aef9027cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input image shape: (10, 10)\n",
            "\n",
            "After Conv Layer (feature maps shape): (8, 8, 8)\n",
            "\n",
            "After Max Pooling Layer (downsampled maps shape): (8, 4, 4)\n",
            "\n",
            "After Flatten Layer (vector length): 128\n",
            "\n",
            "Final ANN Output (logits for 10 classes):\n",
            " [  65.6665202   -42.26949394   90.79486478  -77.063693     -8.16801771\n",
            "  -18.14976095 -132.2134485   -19.93759681  -20.88200213   98.68954855]\n",
            "\n",
            "Final Probabilities:\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "\n",
            "Predicted Class: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IHLcLOhmOOLy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}